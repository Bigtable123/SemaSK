{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import re\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path from here\n",
    "input_path = 'your_path.csv' # POI data\n",
    "output_path = 'your_path.csv' # where to save the data\n",
    "\n",
    "test = pd.read_csv('your_path.csv') #testset\n",
    "input = pd.read_csv(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = input_path \n",
    "metadata_columns = ['business_id','name','longitude', 'latitude']\n",
    "loader = CSVLoader(\n",
    "    file_path=file_path,\n",
    "    metadata_columns=metadata_columns,\n",
    "    csv_args={\n",
    "        'delimiter': ',',\n",
    "        'quotechar': '\"',\n",
    "    }\n",
    ")\n",
    "\n",
    "data = loader.load()\n",
    "for doc in data:\n",
    "    doc.metadata['longitude'] = float(doc.metadata['longitude'])\n",
    "    doc.metadata['latitude'] = float(doc.metadata['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [doc.page_content for doc in data]\n",
    "tokenized_documents = [word_tokenize(doc.lower()) for doc in documents]\n",
    "tokenized_documents = [[word for word in doc if word not in stop_words and word.isalpha()] for doc in tokenized_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_documents)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=15)\n",
    "doc_topics = [lda.get_document_topics(bow) for bow in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_query(query, target_latitude, target_longitude,side_km=5):\n",
    "    tokenized_query = word_tokenize(query.lower())\n",
    "    tokenized_query = [word for word in tokenized_query if word not in stop_words and word.isalpha()]\n",
    "\n",
    "\n",
    "    query_bow = dictionary.doc2bow(tokenized_query)\n",
    "    query_doc_topics = lda.get_document_topics(query_bow)\n",
    "\n",
    "    half_side_km = side_km / 2\n",
    "    delta_lat = half_side_km / 111 \n",
    "\n",
    "    lat_rad = math.radians(target_latitude)\n",
    "\n",
    "    if math.cos(lat_rad) != 0:\n",
    "        delta_lon = half_side_km / (111 * math.cos(lat_rad))\n",
    "    else:\n",
    "        delta_lon = 180  \n",
    "    \n",
    "\n",
    "    scores = []\n",
    "    for i, doc_distribution in enumerate(doc_topics):\n",
    "        score = sum([prob * next((prob for topic_id, prob in doc_distribution if topic_id == topic_id_query), 0)\n",
    "                     for topic_id_query, prob in query_doc_topics])\n",
    "        scores.append((score, i))\n",
    "\n",
    "\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    results = []\n",
    "    for score, index in sorted_scores:\n",
    "        doc = data[index]\n",
    "   \n",
    "        latitude = float(doc.metadata['latitude'])\n",
    "        longitude = float(doc.metadata['longitude'])\n",
    "        \n",
    "        if (target_latitude - delta_lat <= latitude <= target_latitude + delta_lat) and \\\n",
    "           (target_longitude - delta_lon <= longitude <= target_longitude + delta_lon):\n",
    "            results.append(doc)\n",
    "            if len(results) == 10:\n",
    "                break\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_list(s):\n",
    "    s = s.strip('[]')\n",
    "    id_list = s.split(',')\n",
    "    id_list = [id_.strip() for id_ in id_list]\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['id_list'] = test['Answer'].apply(str_to_list)\n",
    "\n",
    "\n",
    "id_to_name = pd.Series(input.name.values, index=input.business_id).to_dict()\n",
    "def map_ids_to_names(id_list, mapping):\n",
    "    return [mapping.get(id_, 'Unknown') for id_ in id_list]\n",
    "\n",
    "\n",
    "test['name_list'] = test['id_list'].apply(lambda x: map_ids_to_names(x, id_to_name))\n",
    "test.drop(['Answer'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = []\n",
    "for _, row in test.iterrows():\n",
    "    question, correct_name = row['Query'], row['name_list']\n",
    "    lat,lon = row['latitude'],row['longitude']\n",
    "\n",
    "\n",
    "    lda_results = lda_query(question,lat,lon)\n",
    "\n",
    "    qa_pairs.append({\n",
    "        \"question\": question,\n",
    "        \"LDA_answer\": [doc.metadata['name'] for doc in lda_results],\n",
    "        \"correct_name\": correct_name\n",
    "    })\n",
    "\n",
    "qa_df = pd.DataFrame(qa_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(row):\n",
    "    true_names = set(row['correct_name'])\n",
    "    pred_names = set(row['LDA_answer'])\n",
    "    tp = len(true_names & pred_names)\n",
    "    precision = tp / len(pred_names) if len(pred_names) > 0 else 0\n",
    "    recall = tp / len(true_names) if len(true_names) > 0 else 0\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    return pd.Series({'precision': precision, 'recall': recall, 'f1': f1})\n",
    "\n",
    "\n",
    "qa_df.loc[:, ['precision', 'recall', 'f1']] = qa_df.apply(compute_metrics, axis=1)\n",
    "\n",
    "\n",
    "avg_precision = qa_df['precision'].mean()\n",
    "avg_recall = qa_df['recall'].mean()\n",
    "avg_f1 = qa_df['f1'].mean()\n",
    "\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1 Score: {avg_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df.to_csv(output_path,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
