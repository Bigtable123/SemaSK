{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from operator import itemgetter\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from qdrant_client import models\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "import ast\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import re\n",
    "from math import radians, cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path from here\n",
    "input_path = 'your_path.csv' # POI data\n",
    "output_path = 'your_path.csv' # where to save the data\n",
    "\n",
    "test = pd.read_csv('your_path.csv') #testset\n",
    "input = pd.read_csv(input_path)\n",
    "\n",
    "# change openai api key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.loc[test['Answer'] != '[]']\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"mixedbread-ai/mxbai-embed-large-v1\", cache_folder=embedding_path)\n",
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "\n",
    "file_path = input_path\n",
    "metadata_columns = ['business_id','name','longitude', 'latitude']\n",
    "loader = CSVLoader(\n",
    "    file_path=file_path,\n",
    "    metadata_columns=metadata_columns,\n",
    "    csv_args={\n",
    "        'delimiter': ',',\n",
    "        'quotechar': '\"',\n",
    "    }\n",
    ")\n",
    "\n",
    "data = loader.load()\n",
    "for doc in data:\n",
    "    doc.metadata['longitude'] = float(doc.metadata['longitude'])\n",
    "    doc.metadata['latitude'] = float(doc.metadata['latitude'])\n",
    "\n",
    "# store data in vector database\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=data, \n",
    "    embedding=embeddings, \n",
    "    path = 'vectoreDB', \n",
    "    collection_name=\"yelp_colls\",\n",
    "    force_recreate=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set llm to gpt-4o\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "rag_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\"You are an assistant for location information sorting tasks. Below is the location information retrieved from the database,\\\n",
    "            which will be given to you in JSON format. You are asked to filter and sort this information based on the question asked. You first need to determine whether the information is relevant to the question, and then sort all the relevant information. The ones that best match the \\\n",
    "            question and help answer it have the highest priority. The format of your output must be a Python dictionary, where the key is the name of the location and the value is the reason why you chose this location and ranked it there. The location with the highest priority is placed higher, i.e., index is 0. \\\n",
    "            Please note that there could be more than one result in the dictionary. If the information about a location could only partially match the question asked, you could also put it in the dictionary, but specify the advantages and disadvantages of this place in the value of the dictionary. \\\n",
    "            If you could not complete the task or do not know the answer, just return the empty dictionary and do not refer to any additional knowledge\"\n",
    "     \n",
    "        ),\n",
    "        (\"human\", \"information:{context}\\nquestion:{question}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set llm to gpt-o1\n",
    "# llm = ChatOpenAI(temperature=1, model=\"o1-preview\")\n",
    "# rag_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"human\",\"You are an assistant for location information sorting tasks. Below is the location information retrieved from the database,\\\n",
    "#             which will be given to you in JSON format. You are asked to filter and sort this information based on the question asked. You first need to determine whether the information is relevant to the question, and then sort all the relevant information. The ones that best match the \\\n",
    "#             question and help answer it have the highest priority. The format of your output must be a Python dictionary, where the key is the name of the location and the value is the reason why you chose this location and ranked it there. The location with the highest priority is placed higher, i.e., index is 0. \\\n",
    "#             Please note that there could be more than one result in the dictionary. If the information about a location could only partially match the question asked, you could also put it in the dictionary, but specify the advantages and disadvantages of this place in the value of the dictionary. \\\n",
    "#             If you could not complete the task or do not know the answer, just return the empty dictionary and do not refer to any additional knowledge\"\n",
    "     \n",
    "#         ),\n",
    "#         (\"human\", \"information:{context}\\nquestion:{question}\"),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global ans\n",
    "@chain\n",
    "def find_query(_dict,vectorstore=vectorstore):\n",
    "    query = _dict['query']\n",
    "    lat = _dict['lat']\n",
    "    lon = _dict['lon']\n",
    "    global ans  \n",
    "\n",
    "    side_km = 5\n",
    "\n",
    "    half_side_km = side_km / 2\n",
    "    delta_lat = half_side_km / 111  \n",
    "    delta_lon = half_side_km / (111 * np.cos(radians(lat)))\n",
    "\n",
    "    filter = models.Filter(\n",
    "        must=[\n",
    "            models.FieldCondition(\n",
    "                key=\"metadata.latitude\",\n",
    "                range=models.Range(\n",
    "                    gte=lat - delta_lat,  \n",
    "                    lte=lat + delta_lat,  \n",
    "                ),\n",
    "            ),\n",
    "            models.FieldCondition(\n",
    "                key=\"metadata.longitude\",\n",
    "                range=models.Range(\n",
    "                    gte=lon - delta_lon,  \n",
    "                    lte=lon + delta_lon,  \n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    ans = vectorstore.similarity_search(query,k=10,filter=filter)\n",
    "    docs_content = [doc.page_content for doc in ans]\n",
    "    global_docs_content = json.dumps(docs_content, ensure_ascii=False, indent=4)\n",
    "    return global_docs_content\n",
    "\n",
    "\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": {\"query\":itemgetter(\"question\"),\"lat\":itemgetter(\"lat\"),\"lon\":itemgetter(\"lon\")} | find_query,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "df = test.copy()\n",
    "\n",
    "qa_pairs = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "\n",
    "    question, correct_ans = row['Query'], row['Answer']\n",
    "    lat,lon = row['latitude'], row['longitude']\n",
    "\n",
    "    answer = qa_chain.invoke({\"question\": question , \"lat\": lat, \"lon\": lon})\n",
    "    # rank_dict = ast.literal_eval(answer)\n",
    "    # rank_list = list(rank_dict.items())\n",
    "    # best_key, best_value = rank_list[0]\n",
    "\n",
    "    # normalized_ans = normalize_text(correct_ans)\n",
    "    # found = any(normalized_ans in normalize_text(key) for key in rank_dict.keys())\n",
    "\n",
    "    qa_pairs.append({\n",
    "        \"question\": question,\n",
    "        # \"LLM_answer\": list(rank_dict.keys()),\n",
    "        \"ans\":answer,\n",
    "        \"correct_ans\": correct_ans,\n",
    "        \"docs\": ans  \n",
    "    })\n",
    "\n",
    "qa_df = pd.DataFrame(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_list(s):\n",
    "    s = s.strip('[]')\n",
    "    id_list = s.split(',')\n",
    "    id_list = [id_.strip() for id_ in id_list]\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df['id_list'] = qa_df['correct_ans'].apply(str_to_list)\n",
    "\n",
    "\n",
    "id_to_name = pd.Series(input.name.values, index=input.business_id).to_dict()\n",
    "def map_ids_to_names(id_list, mapping):\n",
    "    return [mapping.get(id_, 'Unknown') for id_ in id_list]\n",
    "\n",
    "\n",
    "qa_df['name_list'] = qa_df['id_list'].apply(lambda x: map_ids_to_names(x, id_to_name))\n",
    "qa_df.drop(['correct_ans'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dict_from_codeblock(code_str):\n",
    "    start_marker = '```python\\n'\n",
    "    end_marker = '\\n```'\n",
    "\n",
    "    if '```python' in code_str:\n",
    "        start_idx = code_str.find(start_marker)\n",
    "        if start_idx == -1:\n",
    "            raise ValueError(\"Error, no ```python\")\n",
    "        end_idx = code_str.find(end_marker, start_idx)\n",
    "        if end_idx == -1:\n",
    "            raise ValueError(\"Error, no ending ``` after ```python\")\n",
    "        dict_str = code_str[start_idx + len(start_marker):end_idx].strip()\n",
    "    else:\n",
    "        dict_str = code_str.strip()\n",
    "\n",
    "\n",
    "    try:\n",
    "        data_dict = json.loads(dict_str)\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            data_dict = ast.literal_eval(dict_str)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"JSON Error: {e}\")\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = qa_df[~qa_df['name_list'].apply(lambda x: x == ['Unknown'])]\n",
    "qa_df = qa_df.loc[qa_df['ans'] != '{}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df['ans_dict'] = qa_df['ans'].apply(lambda x: extract_dict_from_codeblock(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(row):\n",
    "    true_names = set(row['name_list'])\n",
    "    pred_names = set(row['ans_dict'].keys())\n",
    "    tp = len(true_names & pred_names)\n",
    "    precision = tp / len(pred_names) if len(pred_names) > 0 else 0\n",
    "    recall = tp / len(true_names) if len(true_names) > 0 else 0\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    return pd.Series({'precision': precision, 'recall': recall, 'f1': f1})\n",
    "\n",
    "\n",
    "qa_df.loc[:, ['precision', 'recall', 'f1']] = qa_df.apply(compute_metrics, axis=1)\n",
    "\n",
    "\n",
    "avg_precision = qa_df['precision'].mean()\n",
    "avg_recall = qa_df['recall'].mean()\n",
    "avg_f1 = qa_df['f1'].mean()\n",
    "\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1 Score: {avg_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df.to_csv(output_path,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
